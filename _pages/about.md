---
permalink: /
title: "Welcome to the IDEA Lab"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

The **Intelligent Decision-making for Engineering Applications (IDEA) Lab** at the University of North Carolina at Charlotte focuses on the intersection of **AI, optimization, and systems engineering** to address challenges in modern manufacturing, energy systems, and sustainable operations.

We design and apply **data-driven and algorithmic decision-making frameworks** to enable flexible, efficient, and intelligent engineering solutions.

---

# Research Interests in the IDEA Lab

We pursue interdisciplinary research at the intersection of AI, optimization, and systems engineering. Our lab is currently focused on three key directions:

## Energy Systems Management

<img src='{{ site.baseurl }}/assets/images/Energy-system.png'>

We develop decision-making frameworks for the planning and control of energy systems, with a focus on integrating electric mobility, distributed generation, and energy storage. Our research explores the design and operation of smart microgrids to support multi-modal electrification, grid resilience, and sustainability in emerging energy infrastructures.


## DRL for Advanced Manufacturing Systems 

<img src='{{ site.baseurl }}/assets/images/RL-Manf.png'>

We explore the use of deep reinforcement learning (DRL) to enable adaptive and intelligent control in advanced manufacturing environments. DRL provides a promising framework for handling sequential decisions under uncertainty—such as fluctuating energy availability, dynamic supply and demand, and the production of highly customized products. Our research includes developing transferable DRL algorithms across varying system configurations and applying DRL to additive manufacturing for real-time, flexible process optimization.

## DRL-Augmented Models for Generative Design

<img src='{{ site.baseurl }}/assets/images/RL-gen.png'>

This research explores integrating RL into the diffusion process to guide sample generation toward user-defined goals. By framing each denoising step as an RL-controlled action, we enable iterative, reward-driven fine-tuning of generative models—supporting complex design tasks in domains such as protein engineering and drug discovery.


